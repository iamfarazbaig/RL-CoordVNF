{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "###############################################################\n",
    "# Import packages\n",
    "###############################################################\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../PaperFunctions')\n",
    "sys.path.insert(1, '../Given')\n",
    "import InputConstants\n",
    "from PaperFunctions import Graph, Chains\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################\n",
    "# Reading input files\n",
    "###############################################################\n",
    "input_cons = InputConstants.Inputs()\n",
    "_chain = Chains()\n",
    "_chain.creat_chains_functions(input_cons.chains_random_path + input_cons.chains_random_name,\n",
    "                              input_cons.chains_num,\n",
    "                              input_cons.fun_num,\n",
    "                              input_cons.chain_ban,\n",
    "                              input_cons.cpu_range)\n",
    "functions = _chain.read_funcions(input_cons.chains_random_path + input_cons.chains_random_name)\n",
    "graph = Graph(input_cons.network_path + input_cons.network_name,\n",
    "              functions)\n",
    "chains = _chain.read_chains(input_cons.chains_random_path + input_cons.chains_random_name,\n",
    "                            graph)\n",
    "\n",
    "###############################################################\n",
    "# Learning\n",
    "###############################################################\n",
    "tf.reset_default_graph()\n",
    "node_num = len(graph.node_list)\n",
    "# Define placeholder x for input\n",
    "x = tf.placeholder(dtype=tf.float64, shape=[node_num, input_cons.node_features], name=\"x\")\n",
    "# Define placeholder y for output\n",
    "y = tf.placeholder(dtype=tf.float64, shape=[1, node_num], name=\"y\")\n",
    "# Define variable w and fill it with random number\n",
    "w_1 = tf.Variable(tf.random_normal(shape=[input_cons.node_features, 1], stddev=1e-3, mean=1e-2, dtype=tf.float64),\n",
    "                  name=\"weights_1\", dtype=tf.float64, trainable=True)\n",
    "# w_2 = tf.Variable(tf.random_normal(shape=[5, 1], stddev=1e-3, mean=1e-2, dtype=tf.float64), name=\"weights_2\", dtype=tf.float64, trainable=True)\n",
    "# Define variable b and fill it with zero\n",
    "b_1 = tf.Variable(tf.zeros(1, dtype=tf.float64), name=\"bias_1\", dtype=tf.float64, trainable=True)\n",
    "b_2 = tf.Variable(tf.zeros(1, dtype=tf.float64), name=\"bias_2\", dtype=tf.float64, trainable=True)\n",
    "# Define variable reward and fill it with zero \n",
    "reward = tf.Variable(0, name=\"reward\", dtype=tf.float64)\n",
    "# Define logistic Regression\n",
    "# z_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)\n",
    "# z_1 = tf.matmul(x, w_1)\n",
    "logit = tf.matmul(x, w_1) + b_1\n",
    "logit_mod = tf.reshape(logit, [1, -1])\n",
    "y_predicted = tf.nn.softmax(logit_mod)\n",
    "# Define maximum likelihood loss function\n",
    "loss = -1 * tf.reduce_sum(tf.multiply(y, tf.log(y_predicted +\n",
    "                                                tf.constant(1e-10, dtype=tf.float64))))\n",
    "# loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logit_mod, labels=y)\n",
    "cost = tf.reduce_mean(loss)\n",
    "# Define optimizer: GradientDescent         \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=input_cons.learning_rate)\n",
    "# Compute gradients; grad_pairs contains (gradient, variable) pairs\n",
    "grad_pairs = optimizer.compute_gradients(loss, [w_1, b_1])\n",
    "opt = optimizer.minimize(cost)\n",
    "# Create variables to store accumulated gradients\n",
    "accumulators = [\n",
    "    tf.Variable(\n",
    "        tf.zeros_like(tv.initialized_value()),\n",
    "        trainable=False\n",
    "    ) for tv in [w_1, b_1]\n",
    "]\n",
    "\n",
    "accumulators_stacked = [\n",
    "    tf.Variable(\n",
    "        tf.zeros_like(tv.initialized_value()),\n",
    "        trainable=False\n",
    "    ) for tv in [w_1, b_1]\n",
    "]\n",
    "\n",
    "accumulate_ops = [\n",
    "    accumulator.assign_add(\n",
    "        grad\n",
    "    ) for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)\n",
    "]\n",
    "accumulate_stacked_ops = [\n",
    "    accumulator_s.assign_add(\n",
    "        accumulator\n",
    "    ) for accumulator_s, accumulator in zip(accumulators_stacked, accumulators)]\n",
    "\n",
    "accumulate_mul = [\n",
    "    accumulator.assign_add(\n",
    "        (accumulator * reward) - accumulator\n",
    "    ) for (accumulator, (grad, var)) in zip(accumulators, grad_pairs)\n",
    "]\n",
    "\n",
    "train_step = optimizer.apply_gradients(\n",
    "    [(accumulator, var)\n",
    "     for (accumulator, (grad, var)) in zip(accumulators_stacked, grad_pairs)]\n",
    ")\n",
    "zero_ops = [\n",
    "    accumulator.assign(\n",
    "        tf.zeros_like(tv)\n",
    "    ) for (accumulator, tv) in zip(accumulators, [w_1, b_1])]\n",
    "\n",
    "zero_stacked_ops = [\n",
    "    accumulator.assign(\n",
    "        tf.zeros_like(tv)\n",
    "    ) for (accumulator, tv) in zip(accumulators_stacked, [w_1, b_1])\n",
    "]\n",
    "# %%\n",
    "with tf.Session() as sess: # A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated\n",
    "    graph.make_empty_nodes(chains)\n",
    "    reward_list_1 = []\n",
    "    cost_list_1 = []\n",
    "    rev_list_1 = []\n",
    "    loss_list_1 = []\n",
    "    train_cnt = 0\n",
    "    reward_list = []\n",
    "    reward_list_final = []\n",
    "    cost_list_final = []\n",
    "    cost_list = []\n",
    "    rev_list = []\n",
    "    rev_list_final = []\n",
    "    loss_list = []\n",
    "    loss_list_final = []\n",
    "    tf.local_variables_initializer().run()\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(input_cons.epoch_num):\n",
    "        placed_chains = []\n",
    "        graph.make_empty_nodes(chains)\n",
    "        node_fun_list = []\n",
    "        grads_stack = 0\n",
    "        cnt = 0\n",
    "        node_fun = []\n",
    "        mf_matrix = graph.update_feature_matrix(node_fun)\n",
    "        ser_name_list = []\n",
    "        for ser_num, s in enumerate(chains):\n",
    "            node_fun = []\n",
    "            ser_name_list.append(s.name)\n",
    "            for fun in s.fun:\n",
    "                y_RL = sess.run(y_predicted, feed_dict={x: mf_matrix})\n",
    "                y_one_hot, candidate = graph.select_one(y_RL,\n",
    "                                                        approach='sample')\n",
    "                loss_list.append(sess.run(cost, feed_dict={y: y_RL, x: mf_matrix}))\n",
    "                gradient_val = sess.run(accumulate_ops, feed_dict={x: mf_matrix, y: y_one_hot})\n",
    "                node_fun.append((candidate, fun))\n",
    "                mf_matrix = graph.update_feature_matrix(node_fun)\n",
    "            node_fun_list.append(node_fun)\n",
    "            reward_val = graph.rev_to_cost(node_fun, ser_num, chains)\n",
    "            sess.run(accumulate_mul, feed_dict={reward: reward_val})\n",
    "            sess.run(accumulate_stacked_ops)\n",
    "            sess.run(zero_ops)\n",
    "            cost_list.append(graph.cost_measure(node_fun,\n",
    "                                                ser_num, chains))\n",
    "            rev_list.append(graph.revenue_measure(node_fun, ser_num,\n",
    "                                                  chains))\n",
    "            reward_list.append(reward_val)\n",
    "            cnt += 1\n",
    "            node_fun = []\n",
    "            if cnt == input_cons.batch_Size:\n",
    "                if (graph.node_is_mapped(node_fun_list, chains) &\n",
    "                        graph.link_is_mapped(node_fun_list, chains)):\n",
    "                    reward_list_1.append(sum(reward_list) / cnt)\n",
    "                    reward_list = []\n",
    "                    loss_list_1.append(sum(loss_list) / cnt)\n",
    "                    loss_list = []\n",
    "                    cost_list_1.append(sum(cost_list) / cnt)\n",
    "                    cost_list = []\n",
    "                    rev_list_1.append(sum(rev_list) / cnt)\n",
    "                    rev_list = []\n",
    "                    train_cnt += 1\n",
    "                    print(\"epoch = \", epoch)\n",
    "                    print(\"Train cnt = \", train_cnt)\n",
    "                    sess.run(train_step)\n",
    "                    w_1_val, b_val = sess.run([w_1, b_1])\n",
    "                    print(\"b_val = \", b_val)\n",
    "                    print(\"w[0]_val = \", w_1_val[0])\n",
    "                    print(\"w[1]_val = \", w_1_val[1])\n",
    "                    print(\"w[2]_val = \", w_1_val[2])\n",
    "                    print(\"w[3]_val = \", w_1_val[3])\n",
    "                    print(\"**********************\")\n",
    "                    graph.batch_function_placement(ser_name_list, node_fun_list)\n",
    "                    ser_name_list = []\n",
    "                    cnt = 0\n",
    "                    sess.run(zero_ops)\n",
    "                    sess.run(zero_stacked_ops)\n",
    "                    node_fun = []\n",
    "                    node_fun_list = []\n",
    "                else:\n",
    "                    loss_list = []\n",
    "                    reward_list = []\n",
    "                    rev_list = []\n",
    "                    cost_list = []\n",
    "                    sess.run(zero_ops)\n",
    "                    sess.run(zero_stacked_ops)\n",
    "                    cnt = 0\n",
    "                    node_fun = []\n",
    "                    node_fun_list = []\n",
    "        if len(reward_list_1) != 0:\n",
    "            reward_list_final.append(sum(reward_list_1) / len(reward_list_1))\n",
    "        reward_list_1 = []\n",
    "        if len(cost_list_1) != 0:\n",
    "            cost_list_final.append(sum(cost_list_1) / len(cost_list_1))\n",
    "        cost_list_1 = []\n",
    "        if len(rev_list_1) != 0:\n",
    "            rev_list_final.append(sum(rev_list_1) / len(rev_list_1))\n",
    "        rev_list_1 = []\n",
    "        if len(loss_list_1) != 0:\n",
    "            loss_list_final.append(sum(loss_list_1) / len(loss_list_1))\n",
    "        loss_list_1 = []\n",
    "###############################################################\n",
    "# Plots\n",
    "###############################################################\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for a in ax.reshape(-1, 1):\n",
    "    a[0].set_xlabel(\"epochs\")\n",
    "ax[0][0].plot(reward_list_final, color='red', label='reward')\n",
    "ax[0][0].legend()\n",
    "ax[1][0].plot(loss_list_final, color='red', label='loss')\n",
    "ax[1][0].legend()\n",
    "ax[0][1].plot(cost_list_final, color='red', label='cost')\n",
    "ax[0][1].legend()\n",
    "ax[1][1].plot(rev_list_final, color='red', label='revenue')\n",
    "ax[1][1].legend()\n",
    "plt.savefig(\"../Plots/newresults6\" + \".pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
